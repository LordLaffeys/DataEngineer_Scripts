{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file 'sad' does not exist. try with correct 'file.json' name or use 'dwh' or 'cc'\n"
     ]
    }
   ],
   "source": [
    "#V1.1\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import openpyxl\n",
    "from openpyxl.styles import PatternFill, Alignment, Border, Side\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime,time\n",
    "import urllib3\n",
    "import pytz\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import pandas as pd \n",
    "from sqlalchemy import create_engine\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "def get_token(username, password):\n",
    "    login_path = \"https://edm-delman.apps.binus.edu/analytic/login\"\n",
    "\n",
    "    payload = json.dumps({\n",
    "        \"username\": username,\n",
    "        \"password\": password\n",
    "    })\n",
    "    headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    token = requests.post(\n",
    "        login_path, \n",
    "        headers=headers, \n",
    "        data=payload, \n",
    "        verify=False\n",
    "    ).headers[\"Authorization\"]\n",
    "    \n",
    "    return token\n",
    "\n",
    "def convert_timezone_to_gmt7(datetime_str):\n",
    "    # Define timezones\n",
    "    utc_timezone = pytz.timezone('Etc/GMT')\n",
    "    gmt7_timezone = pytz.timezone('Asia/Bangkok')  # GMT+0700 is Indochina Time (ICT)\n",
    "    \n",
    "    # Parse the datetime string\n",
    "    dt = datetime.strptime(datetime_str, '%a, %d %b %Y, %H:%M:%S GMT+0000')\n",
    "    \n",
    "    # Localize to UTC timezone\n",
    "    utc_dt = utc_timezone.localize(dt)\n",
    "    \n",
    "    # Convert to GMT+0700 (ICT)\n",
    "    gmt7_dt = utc_dt.astimezone(gmt7_timezone)\n",
    "    \n",
    "    return gmt7_dt.strftime('%a, %d %b %Y, %H:%M:%S GMT+0700')\n",
    "\n",
    "\n",
    "def get_projects_json(proj_file):\n",
    "    if proj_file.lower() == 'dwh':\n",
    "        dwh_url = 'mssql+pyodbc://etl_app:B!N37L4pPU5@edm-dwh.binus.db:1433/dwh?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "        dwh_engine = create_engine(dwh_url)\n",
    "        query = \"SELECT [name], [id], 'name' as init_name, 'Delman' AS [loc] FROM DailyJobCheck\"\n",
    "        \n",
    "        # Execute the query and load the result into a DataFrame\n",
    "        df = pd.read_sql(query, dwh_engine)\n",
    "\n",
    "        # Convert DataFrame to JSON string\n",
    "        json_str = df.to_json(orient='records', indent=4)\n",
    "        return json_str\n",
    "    \n",
    "    elif proj_file.lower() == 'cc':\n",
    "        cc_url = 'mssql+pyodbc://etl_app:4ppB1Nu537L222@edm-comcen.binus.db:1433/CommandCenter_DB?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "        cc_engine = create_engine(cc_url)\n",
    "        query = \"SELECT [name], id, [name] AS init_name, 'Delman' AS [loc] FROM DimDelmanProjectsCC\"\n",
    "        \n",
    "        # Execute the query and load the result into a DataFrame\n",
    "        df = pd.read_sql(query, cc_engine)\n",
    "        \n",
    "        # Convert DataFrame to JSON string\n",
    "        json_str = df.to_json(orient='records', indent=4)\n",
    "        return json_str\n",
    "\n",
    "\n",
    "def generate_excel(token, excel, proj_file=\"projects.json\"):\n",
    "\n",
    "    if proj_file.lower() in ['dwh', 'cc']:\n",
    "        proj_json_str = get_projects_json(proj_file)\n",
    "        proj_dict = json.loads(proj_json_str)\n",
    "\n",
    "    else:\n",
    "        if not os.path.exists(proj_file):\n",
    "            print(f\"The file '{proj_file}' does not exist. try with correct 'file.json' name or use 'dwh' or 'cc'\")\n",
    "            return\n",
    "         \n",
    "        with open(proj_file) as f:\n",
    "            proj_dict = json.load(f)\n",
    "    \n",
    "    proj_url = \"https://edm-delman.apps.binus.edu/analytic/projects/\"\n",
    "\n",
    "    explored = defaultdict(lambda:None)\n",
    "    stat = [\"SUCCESS\", None, \"CREATED\", \"UPSTREAM FAILED\"]\n",
    "\n",
    "    for i, proj in tqdm(enumerate(proj_dict), total=len(proj_dict)):\n",
    "        error_node, error_note = None, None\n",
    "        status = \"\"\n",
    "        if proj[\"id\"] != None:\n",
    "            if explored[proj[\"id\"]] is not None:\n",
    "                note, status = explored[proj[\"id\"]]\n",
    "                _, _ = excel.write_line(proj, i+2, error_note=note, status=status)\n",
    "                continue\n",
    "\n",
    "\n",
    "            schedules = requests.get(\n",
    "                proj_url+proj[\"id\"]+\"/schedules?page_size=8&page=0\",\n",
    "                headers= {'Authorization': token},\n",
    "                verify=False\n",
    "            )\n",
    "            \n",
    "            # Check the schedules time\n",
    "            data = json.loads(schedules.content)['data']       \n",
    "            if data:\n",
    "                for entry in data:\n",
    "                    repeat_period = entry.get('repeat_period', {})\n",
    "                    if entry['repeat_period'] == \"beginning_of_the_month\" :\n",
    "                        continue\n",
    "                    elif 'day_of_week' in repeat_period or 'day' in repeat_period:\n",
    "                        repeat_period = entry['repeat_period']['hour']\n",
    "                        time_object = time(hour=repeat_period, minute=0)\n",
    "                        # Convert to GMT+7\n",
    "                        gmt_offset = 25  # GMT+7 offset in hours\n",
    "                        new_hour = (time_object.hour + gmt_offset) % 24  # Calculate new hour accounting for overflow\n",
    "                        converted_time = time(hour=new_hour, minute=time_object.minute)\n",
    "                        # Define the comparison time (18:00:00)\n",
    "                        comparison_time = time(hour=18, minute=0)\n",
    "                        break\n",
    "                    else :\n",
    "                        repeat_period = entry['repeat_period']['hour']\n",
    "                        time_object = time(hour=repeat_period, minute=0)\n",
    "                        # Convert to GMT+7\n",
    "                        gmt_offset = 7  # GMT+7 offset in hours\n",
    "                        new_hour = (time_object.hour + gmt_offset) % 24  # Calculate new hour accounting for overflow\n",
    "                        converted_time = time(hour=new_hour, minute=time_object.minute)\n",
    "                        # Define the comparison time (18:00:00)\n",
    "                        comparison_time = time(hour=18, minute=0)\n",
    "                        break\n",
    "\n",
    "\n",
    "                if converted_time < comparison_time :\n",
    "                    monitoring = requests.get(\n",
    "                    proj_url+proj[\"id\"]+\"/monitoring?page_size=8&page=0\",\n",
    "                    headers= {'Authorization': token},\n",
    "                    verify=False\n",
    "                    )\n",
    "\n",
    "                        # Check the sync date\n",
    "                    data = json.loads(monitoring.content)['data']       \n",
    "                    if data:\n",
    "                        for entry in data:\n",
    "                            if entry.get('started_at'):  # Check if 'started_at' exists and is not None\n",
    "                                date_sync = entry['started_at']\n",
    "                                gmt7_datetime = convert_timezone_to_gmt7(date_sync)\n",
    "                                datetime_obj = datetime.strptime(gmt7_datetime, \"%a, %d %b %Y, %H:%M:%S %Z%z\")\n",
    "                                date_only = datetime_obj.date()\n",
    "                                current_date = datetime.now().date()\n",
    "                                # Perform further operations with date_sync if needed\n",
    "                                break  # Exit the loop once a valid 'started_at' is found\n",
    "                \n",
    "                        if  date_only >= current_date: # check node sync date with the current date\n",
    "                                response = requests.get(\n",
    "                                    proj_url+proj[\"id\"],\n",
    "                                    headers= {'Authorization': token},\n",
    "                                    verify=False\n",
    "                                    )\n",
    "                                \n",
    "                                nodes = json.loads(response.content)['data']['nodes']\n",
    "                                error_node = [n for n in nodes if n['status'] not in stat or n['export_status'] not in stat]\n",
    "                        else:\n",
    "                                status = \"Not Synced\"\n",
    "                                error_note = f'Last Sync at {datetime_obj.strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "                else : \n",
    "                    response = requests.get(\n",
    "                        proj_url+proj[\"id\"],\n",
    "                        headers= {'Authorization': token},\n",
    "                        verify=False\n",
    "                        )\n",
    "                    nodes = json.loads(response.content)['data']['nodes']\n",
    "                    error_node = [n for n in nodes if n['status'] not in stat or n['export_status'] not in stat]\n",
    "            else :\n",
    "                monitoring = requests.get(\n",
    "                    proj_url+proj[\"id\"]+\"/monitoring?page_size=8&page=0\",\n",
    "                    headers= {'Authorization': token},\n",
    "                    verify=False\n",
    "                    )\n",
    "                data = json.loads(monitoring.content)['data']\n",
    "                for entry in data:\n",
    "                    if entry.get('started_at'):  # Check if 'started_at' exists and is not None\n",
    "                        date_sync = entry['started_at']\n",
    "                        gmt7_datetime = convert_timezone_to_gmt7(date_sync)\n",
    "                        datetime_obj = datetime.strptime(gmt7_datetime, \"%a, %d %b %Y, %H:%M:%S %Z%z\")\n",
    "                         # Perform further operations with date_sync if needed\n",
    "                        break  # Exit the loop once a valid 'started_at' is found\n",
    "                status = \"No Schedule\"\n",
    "                error_note = f'Last Sync at {datetime_obj.strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "        \n",
    "        note, status = excel.write_line(proj, i+2, error_nodes=error_node, error_note=error_note, status=status)\n",
    "        explored[proj[\"id\"]] = (note, status)\n",
    "        \n",
    "    excel.save('summary_job.xlsx')\n",
    "\n",
    "class ExcelWriter():\n",
    "    def __init__(self):\n",
    "        self.today = datetime.today().date().strftime(\"%d-%b-%y\")\n",
    "        self.wb = openpyxl.Workbook()\n",
    "        self.sheet = self.wb.active\n",
    "        self.side = Side(border_style='thin', color='000000')\n",
    "        header_border = Side(border_style='thin', color='000000')\n",
    "        self.sheet[\"A1\"] = self.today\n",
    "        self.sheet.merge_cells('A1:L1')\n",
    "        self.sheet[\"A1\"].fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')\n",
    "        self.sheet[\"A1\"].alignment = Alignment(horizontal='center', vertical='center')\n",
    "        self.sheet[\"A1\"].border = Border(left=header_border, right=header_border, top=header_border, bottom=header_border)\n",
    "\n",
    "        self.sheet.column_dimensions['B'].width = 11.43\n",
    "        self.sheet.column_dimensions['C'].width = 11.43\n",
    "        self.sheet.column_dimensions['F'].width = 54.57\n",
    "        self.sheet.column_dimensions['G'].width = 56.71\n",
    "        self.sheet.column_dimensions['H'].width = 12.14\n",
    "        self.sheet.column_dimensions['I'].width = 16\n",
    "        self.sheet.column_dimensions['J'].width = 74.14\n",
    "        \n",
    "        self.colors = {\n",
    "            \"Success\": PatternFill(start_color='C6EFCE', end_color='C6EFCE', fill_type='solid'),\n",
    "            \"Failed\": PatternFill(start_color='FFC7CE', end_color='FFC7CE', fill_type='solid'),\n",
    "            \"Not Synced\": PatternFill(start_color='FFE699', end_color='FFE699', fill_type='solid'),\n",
    "            \"No Schedule\": PatternFill(start_color='BFBFBF', end_color='BFBFBF', fill_type='solid'),\n",
    "            \"\": PatternFill(start_color='FFFFFF', end_color='FFFFFF', fill_type='solid')\n",
    "        }\n",
    "\n",
    "    def write_line(self, proj, row_id,error_nodes=None, error_note=None,status=\"\"):\n",
    "        if error_note == None:\n",
    "            error_note = \"\"\n",
    "            if error_nodes is None:\n",
    "                pass\n",
    "            elif len(error_nodes) <= 5:\n",
    "                for n in error_nodes:\n",
    "                    if n[\"status\"] != \"SUCCESS\":\n",
    "                        error_note += f\"{n['name']} --> {n['status']}\\n\"\n",
    "                    else:\n",
    "                        error_note += f\"{n['name']} --> export {n['export_status']}\\n\"\n",
    "            else:\n",
    "                error_note = \"error in more than 5 nodes\"\n",
    "                \n",
    "            if error_nodes == None:\n",
    "                pass\n",
    "            elif len(error_nodes) > 0:\n",
    "                status = \"Failed\"\n",
    "            else:\n",
    "                status = \"Success\"\n",
    "\n",
    "        self.sheet[\"A\" + str(row_id)].fill = PatternFill(start_color='000000', end_color='000000', fill_type='solid')\n",
    "        self.sheet[\"B\" + str(row_id)] = self.today\n",
    "        self.sheet[\"C\" + str(row_id)] = datetime.today().strftime(\"%H:%M\")\n",
    "        self.sheet[\"F\" + str(row_id)] = proj[\"init_name\"]\n",
    "        self.sheet[\"G\" + str(row_id)] = proj[\"name\"]\n",
    "        self.sheet[\"H\" + str(row_id)] = proj[\"loc\"]\n",
    "        self.sheet[\"I\" + str(row_id)] = status\n",
    "        self.sheet[\"I\" + str(row_id)].fill = self.colors[status]\n",
    "        self.sheet[\"J\" + str(row_id)] = error_note\n",
    "        self.sheet[\"L\" + str(row_id)] = \"Success\" if status==\"Success\" else \"\"\n",
    "        if status == \"Success\":\n",
    "            self.sheet[\"L\" + str(row_id)].fill = self.colors[status]\n",
    "        \n",
    "        for cell in self.sheet['A'+str(row_id):'L'+str(row_id)][0]:\n",
    "            cell.border = Border(left=self.side, right=self.side, top=self.side, bottom=self.side)\n",
    "        \n",
    "        return error_note, status\n",
    "        \n",
    "    def save(self, name):\n",
    "        self.wb.save(name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "    load_dotenv(override=True)\n",
    "    username = os.environ.get(\"USERNAME_DELMAN\")\n",
    "    password = os.environ.get(\"PASSWORD_DELMAN\")\n",
    "    token = get_token(\"jovian.yanto@binus.edu\", \"Jovian@123\")\n",
    "    excel = ExcelWriter()\n",
    "    generate_excel(token, excel, *sys.argv[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MigrationUAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
